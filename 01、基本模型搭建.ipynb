{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T12:29:24.254298Z",
     "start_time": "2019-05-15T12:29:24.243103Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入包\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input, Dense, Activation, Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T12:41:08.286319Z",
     "start_time": "2019-05-15T12:41:08.225157Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "# 序列模型的实现\n",
    "model = Sequential()\n",
    "\n",
    "# 模型第一层要说明输入向量的维度，样本数就不用（输入层为 784 个节点，有 32 个隐藏层节点）\n",
    "# 第一层是 输入层 与 第一层隐藏层 之间的全连接，需要指定输入层的大小\n",
    "model.add(Dense(units=32, input_shape=(784,)))\n",
    "\n",
    "# 激活函数（使用 relu 函数作为隐藏层的激活函数 ，）\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 全连接层（输出层层， 10 个节点）\n",
    "# 这里的全连接层(本例中)是 隐藏层 与 输出层 之间的全连接层。\n",
    "# 输入参数由 隐藏层 给出，因此不需要说明输入向量的维度\n",
    "model.add(Dense(units=10))\n",
    "\n",
    "# 激活函数（使用 softmax 作为输出层的激活函数）\n",
    "# 作为 输出层 使用的激活函数\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-15T12:46:25.076077Z",
     "start_time": "2019-05-15T12:46:25.039175Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用通用模型\n",
    "# 首先要使用 Input 函数将输入转化为一个 tensor ，然后将每一层用变量存储后，\n",
    "# 作为下一层的参数，最后使用 Model 将输入和输出作为参数即可搭建模型。\n",
    "\n",
    "x_input = Input(shape=(784,))  # Input 将输入变成张量\n",
    "dense_1 = Dense(units=32)(x_input)\n",
    "act_1 = Activation('relu')(dense_1)\n",
    "output = Dense(units=10, activation='softmax')(act_1)\n",
    "model = Model(inputs=x_input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型优化和训练\n",
    "\n",
    "# 1、\n",
    "# compile(optimizer, loss, metrics=None)\n",
    "# 参数说明：\n",
    "# optimizer：优化器，如： 'SGD', 'Adam' 等，导入 from keras.optimizers import SGD, Adam\n",
    "# loss：定义模型的损失函数，如： 'mse', 'mae', 'categorical_crossentropy'等\n",
    "# metric：模型的评价指标，如： 'accuracy'等\n",
    "\n",
    "# 2、\n",
    "# fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, validation_split=0.0)\n",
    "# 参数说明：\n",
    "# x：输入数据\n",
    "# y：标签\n",
    "# batch_size：梯度下降时每个 batch 包含的样本数\n",
    "# epochs：整数，所有样本的训练次数\n",
    "# verbose：日志显示，0 为不显示，1 为显示进度条记录，2 为每个epochs输出一行记录\n",
    "# validation_split：0-1 的浮点数，切割输入数据的一定比例作为验证集。\n",
    "\n",
    "# 优化器定义为 SGD ，损失函数定义为 mse ， 评价指标定义为 accuracy （准确率）\n",
    "model.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 每次训练 32 个数据， 所有样本训练 3 次， 选出 30% 作为验证集\n",
    "model.fit(x,y,batch_size=32,epochs=3,validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
